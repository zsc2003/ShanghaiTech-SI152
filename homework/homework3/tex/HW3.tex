\documentclass[10pt]{article}
\usepackage[UTF8]{ctex}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage{amsthm}
\usepackage{amsmath,amscd}
\usepackage{amssymb,array}
\usepackage{amsfonts,latexsym}
\usepackage{graphicx,subfig,wrapfig}
\usepackage{times}
\usepackage{psfrag,epsfig}
\usepackage{verbatim}
\usepackage{tabularx}
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}
\usepackage{cite}
\usepackage{algorithm}
\usepackage{multirow}
\usepackage{caption}
\usepackage{algorithmic}
%\usepackage[amsmath,thmmarks]{ntheorem}
\usepackage{listings}
\usepackage{color}
\usepackage{bm}



\newtheorem{thm}{Theorem}
\newtheorem{mydef}{Definition}

\DeclareMathOperator*{\rank}{rank}
\DeclareMathOperator*{\trace}{trace}
\DeclareMathOperator*{\acos}{acos}
\DeclareMathOperator*{\argmax}{argmax}


\renewcommand{\algorithmicrequire}{ \textbf{Input:}}
\renewcommand{\algorithmicensure}{ \textbf{Output:}}
\renewcommand{\mathbf}{\boldsymbol}
\newcommand{\mb}{\mathbf}
\newcommand{\matlab}[1]{\texttt{#1}}
\newcommand{\setname}[1]{\textsl{#1}}  
\newcommand{\Ce}{\mathbb{C}}
\newcommand{\Ee}{\mathbb{E}}
\newcommand{\Ne}{\mathbb{N}}
\newcommand{\Se}{\mathbb{S}}
\newcommand{\norm}[2]{\left\| #1 \right\|_{#2}}

\newenvironment{mfunction}[1]{
	\noindent
	\tabularx{\linewidth}{>{\ttfamily}rX}
	\hline
	\multicolumn{2}{l}{\textbf{Function \matlab{#1}}}\\
	\hline
}{\\\endtabularx}

\newcommand{\parameters}{\multicolumn{2}{l}{\textbf{Parameters}}\\}

\newcommand{\fdescription}[1]{\multicolumn{2}{p{0.96\linewidth}}{

		\textbf{Description}

		#1}\\\hline}

\newcommand{\retvalues}{\multicolumn{2}{l}{\textbf{Returned values}}\\}
\def\0{\boldsymbol{0}}
\def\b{\boldsymbol{b}}
\def\bmu{\boldsymbol{\mu}}
\def\e{\boldsymbol{e}}
\def\u{\boldsymbol{u}}
\def\x{\boldsymbol{x}}
\def\v{\boldsymbol{v}}
\def\w{\boldsymbol{w}}
\def\N{\boldsymbol{N}}
\def\X{\boldsymbol{X}}
\def\Y{\boldsymbol{Y}}
\def\A{\boldsymbol{A}}
\def\B{\boldsymbol{B}}
\def\y{\boldsymbol{y}}
\def\cX{\mathcal{X}}
\def\transpose{\top} % Vector and Matrix Transpose

%\long\def\answer#1{{\bf ANSWER:} #1}
\long\def\answer#1{}
\newcommand{\myhat}{\widehat}
\long\def\comment#1{}
\newcommand{\eg}{{e.g.,~}}
\newcommand{\ea}{{et al.~}}
\newcommand{\ie}{{i.e.,~}}

\newcommand{\db}{{\boldsymbol{d}}}
\renewcommand{\Re}{{\mathbb{R}}}
\newcommand{\Pe}{{\mathbb{P}}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\hyphenation{MATLAB}

\usepackage[margin=1in]{geometry}

\begin{document}

\title{	Numerical Optimization, 2023 Fall\\Homework 3}
\date{Due 23:59 (CST), Nov. 16, 2023 }

\author{
    Name: \textbf{Zhou Shouchen} \\
	Student ID: 2021533042
}

\maketitle
\newpage

%===============================

\begin{problem}{1}
    Prove the dual of the dual of a linear programming (standard form) is itself.\textcolor{red}{[25pts]}
\end{problem}
We can prove this with the help of the Duality Scheme.\\
Consider a linear programming that is in standard form:\\
\begin{equation}
\begin{aligned}
\min_{\bm{x}} \quad & \bm{c}^T\bm{x} \\
\text { s.t. } \quad & A\bm{x} = \bm{b} \\
& \bm{x} \geq \bm{0}
\end{aligned}
\end{equation}

Since for the primal question, the variables are $\bm{x}\geq 0$, so for $x_i\geq 0$, the dual constrain is that:\\
$$a_i^T\bm{\lambda} \leq c_i$$
where $a_i$ is the $i$-th column of $A$.\\

So for the dual problem, the constrains are $A^T\bm{\lambda} \leq \bm{c}$.\\

And since for the primal question, the constrain it that $A\bm{x} = \bm{b}$, i.e.$\sum\limits_{j=1}^na_{ij}x_j=b_i$.\\
So for the dual question, the variables $\bm{\lambda}$ is free.\\

So the dual problem is that:\\
\begin{equation}
\begin{aligned}
\max_{\bm{\lambda}} \quad & \bm{\lambda}^T\bm{b} \\
\text { s.t. } \quad & A^T\bm{\lambda} \leq \bm{c} \\
& \bm{\lambda} \text{ is free}
\end{aligned}
\end{equation}

To easily get the dual of the dual problem, we can first convert the objective function of the dual problem to a minimization problem. And take $M=A^T$,
the dual problem becomes:
\begin{equation}
\begin{aligned}
\min_{\bm{\lambda}} \quad & \bm{\lambda}^T\bm{(-b)} \\
\text { s.t. } \quad & M\bm{\lambda} \leq \bm{c} \\
& \bm{\lambda} \text{ is free}
\end{aligned}
\end{equation}

The Lagrangian of the dual problem is:\\
$$L(\bm{\lambda},\bm{y}) = \bm{\lambda}^T\bm{(-b)} - \bm{y}^T(M\bm{\lambda} - \bm{c})$$
The dual objective function of the dual problem is that:
$$g(\bm{y}) = \min\limits_{\bm{\lambda}} L(\bm{\lambda},\bm{y})=\min\limits_{\bm{\lambda}}\bm{\lambda}^T\bm{(-b)} - \bm{y}^T(M\bm{\lambda} - \bm{c})
=\bm{y}^T\bm{c}-(\bm{b}^T+\bm{y}^TM)\bm{\lambda}$$

Since for the dual objective function, the variables are $\bm{\lambda}\text{ is free}$, to avoid $g(\bm{y})=-\infty$, we need to constrain that $\bm{b}^T+\bm{y}^TM=\bm{0}$.\\
So for the dual problem, the constrains are
$$M^T\bm{y} = \bm{-b}$$

And since for the dual question, the constrain it that $M\bm{\lambda} \leq \bm{c}$, i.e.$\sum\limits_{j=1}^nm_{ij}\lambda_j\leq c_i$.\\
so for the dual question, the variables are $\bm{y}\leq\bm{0}$.

So the dual of the dual problem is that:\\
\begin{equation}
\begin{aligned}
\max_{\bm{y}} \quad & \bm{c}^T\bm{y} \\
\text { s.t. } \quad & M^T\bm{y} = \bm{-b} \\
& \bm{y} \leq \bm{0}
\end{aligned}
\end{equation}

We can take $\bm{x}=-\bm{y}$. And since $M=A^T$, so $M^T=(A^T)^T=A$.

Consider the objective function is 
$$\max\limits_{\bm{y}} \quad \bm{c}^T\bm{y}$$
We can convert it into a minimization problem by taking $-\bm{y}$ as the variable.\\
i.e.
$$\min\limits_{\bm{y}} \quad \bm{c}^T\bm{(-y)}$$
And since we have $\bm{x}=-\bm{y}$, so we can convert the above minimization problem into:
$$\min\limits_{\bm{x}} \quad \bm{c}^T\bm{x}$$

And for the first constrain, we have:
$$M^T\bm{y} = \bm{-b}$$
Since $M^T=A$, and move the "-" from the right to the left, we have:
$$A\bm{(-y)} = \bm{b}$$
i.e.
$$A\bm{x} = \bm{b}$$

For the second constrain, we have:
$$\bm{y}\leq\bm{0}$$
We can convert it into:
$$\bm{-y}\geq\bm{0}$$
i.e.
$$\bm{x}\geq\bm{0}$$

So with the convertions above, we can get that the dual of the dual problem is that:
\begin{equation}
\begin{aligned}
\min_{\bm{x}} \quad & \bm{c}^T\bm{x} \\
\text { s.t. } \quad & A\bm{x} = \bm{b} \\
& \bm{x} \geq \bm{0}
\end{aligned}
\end{equation}

Which is exactly same with the primal problem.\\
So above all, the dual of the dual of a linear programming (standard form) is itself.\\

\newpage

% %===============================

\begin{problem}{2}
    Prove the dual objective increases after a pivot of the dual simplex method.\textcolor{red}{[25pts]}
\end{problem}

Consider the dual simplex method.\\
Suppose that the current state is feasible, and after the pivot, it is also feasible.\\
Then for the pivot process, we have:\\
The reduced cost $\bm{r}^T\geq \bm{0}$ always satisfies, this is to make sure the dual problem is feasible.\\
Suppose that the right vector is $\bar{\bm{b}}$.\\ 
And suppose that for the current pivot, we choose the $p$-th row s.t. the current $\bar{b}_p$ in the tableau is nagetive.\\
i.e. $\bar{b}_p<0$.\\
Suppose that the elements in the $p$-th row are $y_{p1},y_{p2},\cdots,y_{pn},\bar{b}_p$, and we choose the pivot element $y_{pq}$.\\
Where $\hat{\epsilon}=\dfrac{r_q}{-y_{pq}} = \min\{\dfrac{r_i}{-y_{pi}}\mid y_{pi}<0,i=1,\cdots,n\}$.\\
Then we pivot with $y_{pq}$, and we need to update the tableau to make the $r_q$ become $0$ by:\\
Let the last row of the simplex tableau adds $\hat{\epsilon}$ times the $p$-th row.\\
So we have
$$r_q'=r_q+\hat{\epsilon}y_{pq}=r_q+\dfrac{r_q}{-y_{pq}}y_{pq}=0$$
$$-f'=-f+\hat{\epsilon}\bar{b}_p$$

We know that before the pivot, the lower-right corner is $-f$, where $f$ is the dual objective value of the dual problem.\\
So after the pivot, the lower-right corner becomes:\\
$$-f'=-f+\hat{\epsilon}\bar{b}_p$$
Since $r_q>0,y_{pq}<0$, so $\hat{\epsilon}=\dfrac{r_q}{-y_{pq}}>0$. \\
And since $\bar{b}_p<0$, so $\hat{\epsilon}\bar{b}_p<0$.\\
So
$$-f'= -f +\hat{\epsilon}\bar{b}_p < -f$$
i.e.
$$f'>f$$
So the objective value of the dual problem increases after the pivot.\\
And we can also see this in another conspect.\\
Let $\hat{\bm{\lambda}}^T=\bm{\lambda}^T+\dfrac{r_p}{y_{pq}}\bm{u}_p$, where $\bm{u}_p$ is the $p$-th row of $B^{-1}$.\\
Then we have: $\hat{\bm{\lambda}}^T\bm{b}=\bm{\lambda}^T\bm{b}-\hat{\epsilon}\bar{b}_p$.\\
Since $\hat{\epsilon}\bar{b}_p<0$, so $\hat{\bm{\lambda}}^T\bm{b}>\bm{\lambda}^T\bm{b}$.\\
Since $\bm{\lambda}^T\bm{b}$ is the objective value of the dual problem before pivot, and $\hat{\bm{\lambda}}^T\bm{b}$ is the objective value of the dual problem after pivot, so the objective value of the dual problem increases after the pivot.\\

So above all, we have prove that the dual objective increases after a pivot of the dual simplex method.\\

\newpage

% %===============================

\begin{problem}{3}
    Let $L(\bm{x}, \bm{\lambda})$ be the Lagrangian of a linear programming problem, and $(\bm{x}^*, \bm{\lambda}^*)$ be the optimal primal-dual solution. Prove that $$L(\bm{x}, \bm{\lambda}^*) \geq L(\bm{x}^*, \bm{\lambda}^*) \geq L(\bm{x}^*, \bm{\lambda}),$$ for any primal feasible $\bm{x}$ and dual feasible $\bm{\lambda}$.\textcolor{red}{[25pts]}
\end{problem}

Suppose that the primal problem is that
\begin{equation}
\begin{aligned}
\min_{\bm{x}} \quad & \bm{c}^T\bm{x} \\
\text { s.t. } \quad & A\bm{x} \leq \bm{b} \\
\end{aligned}
\end{equation}

Then the Lagrangian of the primal problem is that:
$$L(\bm{x},\bm{\lambda}) = \bm{c}^T\bm{x} + \bm{\lambda}^T(A\bm{x} - \bm{b})=-\bm{\lambda}^T\bm{b}+(\bm{c}^T+\bm{\lambda}^TA)\bm{x},\bm{\lambda}\geq 0$$
And the primal objective function is
$$f(\bm{x}) = \max\limits_{\bm{\lambda}} L(\bm{x},\bm{\lambda})$$
Since we want to avoid $f(\bm{x})=+\infty$, so we need to constrain that $\bm{c}^T+\bm{\lambda}^TA=0,\bm{\lambda}\geq\bm{0}$.\\
So the dual problem is that:
\begin{equation}
\begin{aligned}
\max_{\bm{\lambda}} \quad & -\bm{\lambda}^T\bm{b} \\
\text { s.t. } \quad & A^T\bm{\lambda} = -\bm{c} \\
& \bm{\lambda} \geq \bm{0}
\end{aligned}
\end{equation}

Then we can prove the inequalities.\\
1. Prove that $L(\bm{x}, \bm{\lambda}^*) \geq L(\bm{x}^*, \bm{\lambda}^*)$.\\
Since $(\bm{x}^*, \bm{\lambda}^*)$ is the optimal primal-dual solution, so we have:\\
According to the strong duality theorem, since the objective value of the dual problem is $-\bm{\lambda}^{*T}\bm{b}$, so we have:
$$\bm{c}^T\bm{x}^* = -\bm{\lambda}^{*T}\bm{b}$$
So
$$L(\bm{x}, \bm{\lambda}^*)=\bm{c}^T\bm{x} + \bm{\lambda}^{*T}(A\bm{x} - \bm{b})=\bm{c}^T\bm{x} + \bm{\lambda}^{*T}A\bm{x} - \bm{\lambda}^{*T}\bm{b}=\bm{c}^T\bm{x} + \bm{\lambda}^{*T}A\bm{x} + \bm{c}^{T}\bm{x}^*$$
And since $\bm{\lambda}^*$ is feasible for the dual problem, so $A^T\bm{\lambda}^* = -\bm{c}$, i.e. $\bm{\lambda}^{*T}A = -\bm{c}^T$.\\
So
$$L(\bm{x},\bm{\lambda}^*)=\bm{c}^T\bm{x} + \bm{\lambda}^{*T}A\bm{x} - \bm{c}^{T}\bm{x}^*=\bm{c}^T\bm{x} - \bm{c}^T\bm{x} + \bm{c}^T\bm{x}^* =\bm{c}^T\bm{x}^* $$

As for $L(\bm{x}^*,\bm{\lambda}^*)$, since we also have $\bm{c}^T\bm{x}^* = -\bm{\lambda}^{*T}\bm{b}$ because of the strong duality theorem.\\
So
$$L(\bm{x}^*, \bm{\lambda}^*)=\bm{c}^T\bm{x}^* + \bm{\lambda}^{*T}A\bm{x}^* - \bm{\lambda}^{*T}\bm{b}=\bm{c}^T\bm{x}^* - \bm{c}^T\bm{x}^* - \bm{\lambda}^{*T}\bm{b}=\bm{c}^T\bm{x}^*$$
So
$$L(\bm{x},\bm{\lambda}^*)= \bm{c}^T\bm{x}^*=L(\bm{x}^*, \bm{\lambda}^*)$$
$$L(\bm{x},\bm{\lambda}^*)=L(\bm{x}^*, \bm{\lambda}^*)\Rightarrow L(\bm{x},\bm{\lambda}^*)\geq L(\bm{x}^*, \bm{\lambda}^*)$$
So we have proved that $L(\bm{x}, \bm{\lambda}^*) \geq L(\bm{x}^*, \bm{\lambda}^*)$.\\

2. Prove that $L(\bm{x}^*, \bm{\lambda}^*) \geq L(\bm{x}^*, \bm{\lambda})$.\\
Since $\bm{\lambda}$ is feasible for the dual problem, so
$$L(\bm{x}^*,\bm{\lambda})=\bm{c}^T\bm{x}^* + \bm{\lambda}^TA\bm{x}^* - \bm{\lambda}^T\bm{b} = \bm{c}^T\bm{x}^* - \bm{c}^T\bm{x}^* - \bm{\lambda}^T\bm{b}=-\bm{\lambda}^T\bm{b}$$

Since the dual objective value is $-\bm{\lambda}^T\bm{b}$\\
So $(-\bm{\lambda}^{*T}\bm{b})\geq (-\bm{\lambda}^T\bm{b})$\\
So
$$L(\bm{x}^*,\bm{\lambda})=-\bm{\lambda}^T\bm{b}\leq -\bm{\lambda}^{*T}\bm{b}$$
From we have proved above, we can get that
$$L(\bm{x}^*, \bm{\lambda}^*)=\bm{c}^T\bm{x}^*=-\bm{\lambda}^{*T}\bm{b}$$
So
$$L(\bm{x}^*,\bm{\lambda})\leq -\bm{\lambda}^{*T}\bm{b}=L(\bm{x}^*, \bm{\lambda}^*)$$

So we have proved that $L(\bm{x}^*, \bm{\lambda}^*) \geq L(\bm{x}^*, \bm{\lambda})$.\\

So above all, we have prove that 
$$L(\bm{x}, \bm{\lambda}^*) \geq L(\bm{x}^*, \bm{\lambda}^*) \geq L(\bm{x}^*, \bm{\lambda})$$

\newpage

% %===============================

\begin{problem}{4}
    Construct a linear programming problem for which both the primal and the dual problem has no feasible solution.\textcolor{red}{[25pts]}

Construct a linear programming problem that is:\\
\begin{equation}
\begin{aligned}
\min_{x_1,x_2} \quad & x_1-2x_2 \\
\text { s.t. } \quad & x_1 - x_2 \leq 1 \\
& x_1 - x_2 \geq 2 \\
% & x_1,x_2 \leq 0
& x_1,x_2 \textcolor{red}{\geq} 0
\end{aligned}
\end{equation}

Since it is impossible to satisfy $x_1 - x_2 \leq 1$ and $x_1 - x_2 \geq 2$ at the same time, so the primal problem has no feasible solution.\\
And the dual problem is that:\\
\begin{equation}
\begin{aligned}
\max_{\lambda_1,\lambda_2} \quad & \lambda_1 + 2\lambda_2 \\
\text { s.t. } \quad & \lambda_1 + \lambda_2 \leq 1 \\
& -\lambda_1 - \lambda_2 \leq -2 \\
& \lambda_1\leq 0,\lambda_2 \geq 0
\end{aligned}
\end{equation}
The second constrain $-\lambda_1 - \lambda_2 \leq -2$ can be written as $\lambda_1 + \lambda_2 \geq 2$.\\
Since it is impossible to satisfy $\lambda_1 + \lambda_2 \leq 1$ and $\lambda_1 + \lambda_2 \geq 2$ at the same time, so the dual problem has no feasible solution.\\

So above all, the above construction's primal and dual problem has no feasible solution.\\

\end{problem}

\end{document}


